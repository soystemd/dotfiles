#!/bin/sh
# download files from given URLs in parallel using aria2c or curl, then open them.
# if you give the same URL again, it will open the already downloaded file.
# if the url is censored, it will download it through tor using torsocks.

# config
parallel=2 # how many files to download in parallel
opener="${OPENER:-xdg-open}" # opener program
torcmd="torsocks" # program that routes traffic through tor
dir="${XDG_RUNTIME_DIR:-$HOME/.cache}/dldir" # where to put the downloaded stuff

main()
{
    totaljobs=$#
    [ $# -eq 1 ] && open_foreground=true

    while true; do

        print_summary

        [ $(donejobs) -eq $totaljobs ] && break
        [ $# -le 0 ] && sleep 0.2 && continue
        [ $(njobs) -ge $parallel ] && sleep 0.2 && continue

        download_and_open "$1" &
        shift

    done

    echo
    echo done.
}

download_and_open()
{
    j=$(newjob)

    url="$1"

    if ! file="$(get_file_from_cache "$url")"; then
        file="$(download "$url")" || return 1
    fi

    if [ "$open_foreground" = true ]; then
        $OPENER "$file"
    else
        nohup $OPENER "$file" >/dev/null 2>&1 &
    fi

    jobdone $j
}

download()
{
    url="$1"
    file="$dir/$(rand_date)"

    dlcmd "$file" "$url" ||
        dlcmd --tor "$file" "$url" || {
            notify-send dl "couldn't download file."
            return 1
        }

    file="$(add_proper_extention_to_file "$file")"
    add_to_cachetable "$file" "$url"

    echo "$file"
    return 0
}

dlcmd()
{
 url   unset tor time ctime
    if [ "$1" = --tor ]; then
        shift
        tor="$torcmd"
        command -v $torcmd >/dev/null || return 1
        ctime=12
        time=20
    fi

    file="$1"
    url="$2"

    if command -v aria2c >/dev/null; then
        $tor aria2c --no-conf -x8 -k1M -s16 -m1 --disable-ipv6=true \
            --connect-timeout=${ctime:-4} --timeout=${time:-6} \
            ${tor:+--async-dns=false} --auto-file-renaming=false \
            -d "$(dirname "$file")" -o "$(basename "$file")" "$url" >/dev/null
    else
        $tor curl --connect-timeout ${ctime:-4} --max-time 300 \
            --xattr -o "$file" "$url" >/dev/null
    fi
}

get_file_from_cache()
{
    [ -r "$cache_table" ] || return 1
    url="$1"
    file="$(awk -v url="$url" '$2==url {print $1; exit}' "$cache_table")"
    [ -n "$file" ] || return 1
    [ -r "$file" ] || return 1
    printf '%s\n' "$file"
    return 0
}

add_to_cachetable()
{
    filev="$1"
    urlv="$2"
    ct="$(printf '%s\t\t%s\n' "$filev" "$urlv"; cat "$cache_table" 2>/dev/null)"
    printf '%s\n' "$ct" > "$cache_table"
}

add_proper_extention_to_file()
{
    oldfile="$1"
    newfile="$oldfile$(get_extention_from_mime "$oldfile")"
    mv -f -- "$oldfile" "$newfile"
    echo "$newfile"
}

get_extention_from_mime()
{
    case "$(file --brief --mime-type -- "$1")" in
        */gif)      echo .gif   ;;
        */png)      echo .png   ;;
        image/*)    echo .jpg   ;;
        *matroska)  echo .mkv   ;;
        video/*)    echo .mp4   ;;
        audio/*)    echo .mp3   ;;
        */pdf)      echo .pdf   ;;
        *photoshop) echo .psd   ;;
        *epub*)     echo .epub  ;;
        */zip)      echo .zip   ;;
        */x-rar*)   echo .rar   ;;
        */x-7z*)    echo .7z    ;;
        */html)     echo .html  ;;
        text/*)     echo .txt   ;;
    esac
}

newjob()
{
    jobname=job-$(rand)
    touch "$tmp_dir/$jobname"
    echo $jobname
}

njobs()
{
    ls -A1 "$tmp_dir" | grep job- | wc -l
}

jobdone()
{
    rm -f "$tmp_dir/$1"
    n="$(donejobs)"
    echo $(( n + 1 )) > "$done_jobs"
}

donejobs()
{
    ndone="$(cat "$done_jobs" 2>/dev/null)"
    if [ -z "$ndone" ]; then
        echo 0 > "$done_jobs"
        echo 0
    else
        echo $ndone
    fi
}

print_summary()
{
    printf '%s/%s complete, %s parallel downloads active\r' $(donejobs) $totaljobs $(njobs)
}

cleanup()
{
    rm -rf "$tmp_dir"
    rmdir "$(dirname "$tmp_dir")"
}

rand()
{
    shuf -n1 -i1000000000-9999999999
}

rand_date()
{
    date +%s | rev | cut -c1-7 | rev | tr -d '\n'
    shuf -n1 -i100-999
}

# set some paths and directories
data_dir="$dir/data"
tmp_dir="$dir/data/jobs/$(rand)"
cache_table="$data_dir/cachetable"
done_jobs="$tmp_dir/donejobs"

# cleanup temp files from past runs,
# set some traps
cleanup 2>/dev/null
mkdir -p "$tmp_dir" || exit 1
trap exit HUP
trap 'cleanup 2>/dev/null; tput cnorm' EXIT
tput civis

main "$@"
exit
